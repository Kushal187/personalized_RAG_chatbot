# ğŸ¯ ResumeAI - Smart Candidate Search

A RAG (Retrieval-Augmented Generation) powered chatbot that enables natural language queries over multiple candidate resumes. Upload PDF resumes and ask questions about candidates using conversational AI.

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://resume-rag-kushal.streamlit.app/)

## ğŸš€ Live Demo

**[Try ResumeAI â†’](https://resume-rag-kushal.streamlit.app/)**

---

## ğŸ“¸ Screenshots

### Empty State
![Empty State](screenshots/empty-state.png)
*Clean interface prompting users to upload resumes and get started*

### Loaded Candidates
![Loaded Candidates](screenshots/demo.gif)
*Demo*

---

## ğŸ› ï¸ Tech Stack

| Technology | Purpose |
|------------|---------|
| **Python 3.8+** | Core programming language |
| **Streamlit** | Web application framework & UI |
| **OpenAI API** | Embeddings (`text-embedding-3-small`) and chat completions (`gpt-4o`, `gpt-4o-mini`) |
| **ChromaDB** | In-memory vector database for semantic search |
| **pdfplumber** | Primary PDF text extraction (complex layouts) |
| **PyPDF2** | Fallback PDF text extraction |
| **python-dotenv** | Environment variable management |

---

## âœ¨ Features

### Core Functionality
- **ğŸ“„ Multi-Resume Upload** â€” Drag and drop PDF resumes (max 2MB each)
- **ğŸ” Semantic Search** â€” Find candidates based on skills, experience, and qualifications using vector similarity
- **ğŸ’¬ Natural Language Queries** â€” Ask questions like "Who has Python experience?" or "Compare candidates with ML background"
- **ğŸ§  Conversation Context** â€” Maintains context across questions with pronoun resolution ("What about his education?")
- **ğŸ“Š Real-time Metrics** â€” Track candidates, indexed chunks, and questions asked

### Advanced RAG Pipeline
- **LLM-based Metadata Extraction** â€” Automatically extracts name, skills, experience, companies, and education from resumes
- **Semantic Chunking** â€” Intelligently splits resumes by sections (experience, skills, education, projects)
- **Temporal Query Expansion** â€” Handles date-based queries ("What was John doing in December 2024?")
- **Query Rewriting** â€” Resolves pronouns and contextual references using conversation history
- **Multi-candidate Queries** â€” Supports comparison queries across all loaded candidates

### Security & Guardrails
- **File Validation** â€” Size limits, PDF magic byte verification
- **Prompt Injection Detection** â€” Blocks malicious content in uploaded documents
- **Query Guardrails** â€” Validates query relevance and blocks injection attempts
- **Response Safety** â€” Filters sensitive information from generated responses
- **Content Sanitization** â€” Removes suspicious Unicode and formatting

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.8+
- OpenAI API key

### Local Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/personalized_RAG_chatbot.git

   cd personalized_RAG_chatbot
   ```

2. **Create a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**
   
   Create a `.env` file in the root directory:
   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   ```

5. **Run the application**
   ```bash
   streamlit run app.py
   ```

6. **Open in browser**
   
   Navigate to `http://localhost:8501`

---


## ğŸ“ Project Structure

```
resumeai/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # Environment variables (local only, not committed)
â”œâ”€â”€ .gitignore             # Git ignore file
â”œâ”€â”€ README.md              # Documentation
â””â”€â”€ screenshots/           # Application screenshots
    â”œâ”€â”€ empty-state.png
    â””â”€â”€ demo.gif
```

---

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENAI_API_KEY` | Your OpenAI API key for embeddings and chat | Yes |

### Model Configuration

The application uses the following OpenAI models (configurable in `app.py`):

| Constant | Model | Purpose |
|----------|-------|---------|
| `EMBED_MODEL` | `text-embedding-3-small` | Document and query embeddings |
| `CHAT_MODEL` | `gpt-4o-mini` | Query rewriting, temporal expansion |
| `ANSWER_MODEL` | `gpt-4o` | Final answer generation |
| `EXTRACTION_MODEL` | `gpt-4o-mini` | Resume metadata extraction |
| `GUARDRAIL_MODEL` | `gpt-4o-mini` | Content validation |

### Other Settings

| Constant | Default | Description |
|----------|---------|-------------|
| `MAX_FILE_SIZE_MB` | 2 | Maximum file size per resume |
| `MAX_CONTEXT_TURNS` | 5 | Conversation turns to maintain |
| `COLLECTION_NAME` | `resumes` | ChromaDB collection name |

---

## ğŸ“ Usage

1. **Upload Resumes** â€” Use the sidebar to drag & drop or browse for PDF resumes 
2. **Build Index** â€” Click the "Build" button to process and index the resumes
3. **Ask Questions** â€” Type natural language queries in the chat input
4. **Review Sources** â€” Expand the "Sources" section to see which resume chunks were used

### Example Queries

**Single Candidate**
- "Tell me about John's experience"
- "What skills does Sarah have?"

**Temporal Queries**
- "What was John doing in December 2024?"
- "Where did Sarah work in 2023?"

**Multi-Candidate**
- "Who has experience with machine learning?"
- "Compare candidates with Python skills"
- "List all candidates with cloud experience"

**Follow-up Questions**
- "What about his education?" (resolves pronoun from context)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF Upload    â”‚â”€â”€â”€â”€â–¶â”‚   Guardrails     â”‚â”€â”€â”€â”€â–¶â”‚  Text Extract   â”‚
â”‚   (Streamlit)   â”‚     â”‚  (File + Content)â”‚     â”‚ (pdfplumber/    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  PyPDF2)        â”‚
                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â–¼
                        â”‚   LLM Metadata   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                        â”‚   Extraction     â”‚               â”‚
                        â”‚   (gpt-4o-mini)  â”‚               â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
                                 â”‚                         â”‚
                                 â–¼                         â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ Semantic Chunkingâ”‚     â”‚   Sanitization  â”‚
                        â”‚ (by section type)â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    ChromaDB      â”‚
                        â”‚ (Vector Store)   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   User Query    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
         â”‚                       â”‚
         â–¼                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚ Query Rewriting  â”‚             â”‚
â”‚ + Temporal       â”‚             â”‚
â”‚   Expansion      â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
         â”‚                       â”‚
         â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Semantic Search  â”‚â—€â”€â”€â”€â”€â”‚   Embeddings    â”‚
â”‚ (with filters)   â”‚     â”‚ (text-embed-3)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Answer Generationâ”‚
â”‚    (gpt-4o)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Response Safety  â”‚
â”‚   Check          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    [ Response ]
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Streamlit](https://streamlit.io/) for the web framework
- [OpenAI](https://openai.com/) for embedding and language models
- [ChromaDB](https://www.trychroma.com/) for vector storage

---

<p align="center">
  Made with â¤ï¸ by Kushal
</p>